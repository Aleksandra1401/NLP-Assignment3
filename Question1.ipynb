{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xl0K2GQZe8kb"
   },
   "source": [
    "Example of training fastText model and getting sentence embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from scipy import spatial\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HCFRB215b45H"
   },
   "outputs": [],
   "source": [
    "# This method takes in the trained model and the input sentence\n",
    "# and returns the embedding of the sentence as the average embedding\n",
    "# of its words\n",
    "def get_sentence_embedding(model, sentence):\n",
    "\n",
    "    words = sentence.split(\" \")\n",
    "    vector = 0\n",
    "    for word in words:\n",
    "        vector += model.wv[word] \n",
    "    return vector/len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vC6-KZifEAP"
   },
   "source": [
    "Reading Law Stack Exchange Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from post_parser_record import PostParserRecord\n",
    "\n",
    "\n",
    "# Takes in the file path for test file and generate a dictionary\n",
    "# of question id as the key and the list of question ids similar to it\n",
    "# as value. It also returns the list of all question ids that have\n",
    "# at least one similar question\n",
    "def read_tsv_test_data(file_path):\n",
    "    \n",
    "    dic_similar_questions = {}\n",
    "    lst_all_test = []\n",
    "    with open(file_path) as fd:\n",
    "        rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "        for row in rd:\n",
    "            question_id = int(row[0])\n",
    "            lst_similar = list(map(int, row[1:]))\n",
    "            dic_similar_questions[question_id] = lst_similar\n",
    "            lst_all_test.append(question_id)\n",
    "            lst_all_test.extend(lst_similar)\n",
    "    return dic_similar_questions, lst_all_test\n",
    "\n",
    "# Initialize, tune and train FastText model.\n",
    "#\n",
    "# lst_sentences - list of strings to train model with\n",
    "def train_model(lst_sentences):\n",
    "    \n",
    "    model = FastText(vector_size = 100, window = 5, negative = 10, min_n=1)\n",
    "    model.build_vocab(lst_sentences)\n",
    "\n",
    "    # training the model\n",
    "    model.train(lst_sentences, total_examples = len(lst_sentences), epochs = 20)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collects and concatenates data from each question. Trains and \n",
    "# saves the model.\n",
    "#\n",
    "# post_file - name of the xml file to read\n",
    "# lst_all_test - list all questions that have duplicates\n",
    "# post_reader - PostReader object\n",
    "def train_and_save_model(post_file, lst_all_test, post_reader):\n",
    "    \n",
    "    lst_training_sentences = []\n",
    "    for question_id in post_reader.map_questions:\n",
    "        # collect data from questions that are not in the tsv file\n",
    "        if question_id in lst_all_test:\n",
    "            continue            \n",
    "        question = post_reader.map_questions[question_id]\n",
    "        title = question.title\n",
    "        body = question.body\n",
    "        sentence = title + body\n",
    "        # Collect sentences here\n",
    "        lst_answers = question.answers\n",
    "        # if there are answers to the question \n",
    "        # add them to sentence\n",
    "        if lst_answers is not None:\n",
    "            for answer in lst_answers:\n",
    "                answer_body = answer.body\n",
    "                # add answer\n",
    "                sentence += answer_body\n",
    "                # drop html tags\n",
    "                sentence = re.sub(r\"(?s)<.*?>\", \"\", sentence)\n",
    "        # add sentence to the list of training sentences\n",
    "        lst_training_sentences.append(sentence)\n",
    "    #train and save\n",
    "    model = train_model(lst_training_sentences)         \n",
    "    model.save(\"fastText.model\") \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided text and model, calculate and return average embedding\n",
    "#\n",
    "# model - FastText model\n",
    "# text - post string\n",
    "def get_average_post_embedding(model, text):\n",
    "    \n",
    "    sentences = sent_tokenize(text)\n",
    "    vectors = []\n",
    "    for sentence in sentences:\n",
    "        vector = get_sentence_embedding(model, sentence)\n",
    "        vectors.append(vector)\n",
    "    average = np.mean(vectors, axis=0)\n",
    "    \n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find similar questions for each question in the test data.\n",
    "# For each question calculate cosine similarity with other questions.\n",
    "#\n",
    "# model - FastText model \n",
    "# post_reader - PostReader object\n",
    "# dic_similar_questions \n",
    "def get_similar_questions(model, post_reader, dic_similar_questions):\n",
    "    \n",
    "    title_dictionary_result = {}\n",
    "    body_dictionary_result = {}\n",
    "    \n",
    "    # finding Similar questions using fastText model\n",
    "    for test_question_id in dic_similar_questions:\n",
    "\n",
    "        # for this question you have to find the similar questions \n",
    "        test_question = post_reader.map_questions[test_question_id]\n",
    "        # drop html\n",
    "        test_title = re.sub(r\"(?s)<.*?>\", \"\", test_question.title )\n",
    "        test_body =  re.sub(r\"(?s)<.*?>\", \"\", test_question.body )\n",
    "        # get embedding for this question\n",
    "        vec1_title = get_average_post_embedding(model, test_title)\n",
    "        vec1_body = get_average_post_embedding(model, test_body)\n",
    "        \n",
    "        cosine_similarity_title = 0\n",
    "        id_title = 0\n",
    "        cosine_similarity_body = 0\n",
    "        id_body = 0\n",
    "        \n",
    "        # for all the questions that aren't this question\n",
    "        for question_id in post_reader.map_questions:\n",
    "            # we are not comparing a question with itself\n",
    "            if question_id == test_question_id:\n",
    "                continue\n",
    "            test_question = post_reader.map_questions[question_id]\n",
    "            # drop html\n",
    "            test_title = re.sub(r\"(?s)<.*?>\", \"\", test_question.title)\n",
    "            test_body =  re.sub(r\"(?s)<.*?>\", \"\", test_question.body)\n",
    "            # get embedding for this question\n",
    "            vec2_title = get_average_post_embedding(model, test_title)\n",
    "            vec2_body = get_average_post_embedding(model, test_body)\n",
    "            # use the model to calculate the cosine similarity between the questions\n",
    "            # save the question id with the highest cosine similarity\n",
    "            # calculating cosine similarity\n",
    "            result_title = 1 - spatial.distance.cosine(vec1_title, vec2_title)\n",
    "           \n",
    "            if result_title > cosine_similarity_title:\n",
    "                cosine_similarity_title = result_title\n",
    "                id_title = question_id   \n",
    "                \n",
    "            result_body = 1 - spatial.distance.cosine(vec1_body, vec2_body)\n",
    "          \n",
    "            if result_body > cosine_similarity_body:\n",
    "                cosine_similarity_body = result_body\n",
    "                id_body = question_id \n",
    "                \n",
    "            \n",
    "        title_dictionary_result[test_question_id] = id_title\n",
    "        body_dictionary_result[test_question_id] = id_body\n",
    "    \n",
    "    return title_dictionary_result, body_dictionary_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7PNV1oxfBbh"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "     \n",
    "\n",
    "    duplicate_file = \"duplicate_questions.tsv\"\n",
    "    post_file = \"Posts_law.xml\"\n",
    "    post_reader = PostParserRecord(post_file)\n",
    "    # load data\n",
    "    dic_similar_questions, lst_all_test = read_tsv_test_data(duplicate_file)\n",
    "    \n",
    "    \n",
    "    # train and save model\n",
    "    model = train_and_save_model(post_file, lst_all_test, post_reader)   \n",
    "    # load model\n",
    "    #model = FastText.load(\"fastText.model\")\n",
    "    \n",
    "    # This dictionary will have the test question id as the key\n",
    "    # and the most similar question id as the value\n",
    "    title_dictionary_result, body_dictionary_result = get_similar_questions(model, post_reader, dic_similar_questions)\n",
    "\n",
    "    p_1 = 0\n",
    "    for key in title_dictionary_result:\n",
    "        if title_dictionary_result[key] in dic_similar_questions[key]:\n",
    "            p_1 += 1\n",
    "    ave = p_1 / len(title_dictionary_result)\n",
    "    \n",
    "    print('Average P@1 for title ', ave)\n",
    "    \n",
    "    p_1 = 0\n",
    "    for key in body_dictionary_result:\n",
    "        if body_dictionary_result[key] in dic_similar_questions[key]:\n",
    "            p_1 += 1\n",
    "    ave = p_1 / len(body_dictionary_result)\n",
    "    \n",
    "    print('Average P@1 for body ', ave)\n",
    "        \n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
